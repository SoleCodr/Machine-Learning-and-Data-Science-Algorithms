{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code for converting an image to black and white image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 41  46  45]\n",
      "  [ 40  45  44]\n",
      "  [ 39  44  43]\n",
      "  ...\n",
      "  [233 237 242]\n",
      "  [233 237 242]\n",
      "  [233 237 242]]\n",
      "\n",
      " [[ 38  43  42]\n",
      "  [ 37  42  41]\n",
      "  [ 36  41  40]\n",
      "  ...\n",
      "  [233 237 242]\n",
      "  [233 237 242]\n",
      "  [233 237 242]]\n",
      "\n",
      " [[ 34  39  38]\n",
      "  [ 34  39  38]\n",
      "  [ 33  38  37]\n",
      "  ...\n",
      "  [233 237 242]\n",
      "  [233 237 242]\n",
      "  [233 237 242]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[140 177 233]\n",
      "  [139 176 232]\n",
      "  [137 174 230]\n",
      "  ...\n",
      "  [ 36  63 113]\n",
      "  [ 35  62 112]\n",
      "  [ 35  62 112]]\n",
      "\n",
      " [[136 174 232]\n",
      "  [131 169 227]\n",
      "  [130 168 226]\n",
      "  ...\n",
      "  [ 36  63 113]\n",
      "  [ 35  62 112]\n",
      "  [ 35  62 112]]\n",
      "\n",
      " [[132 170 228]\n",
      "  [126 164 222]\n",
      "  [126 164 222]\n",
      "  ...\n",
      "  [ 36  63 113]\n",
      "  [ 35  62 112]\n",
      "  [ 35  62 112]]]\n",
      "(600, 800, 3)\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"Katrina_Kaif.jpg\",cv2.IMREAD_GRAYSCALE)   #cv2.IMREAD_COLOR\n",
    "print(img) \n",
    "print(img.shape)   #third arg of shape represents whether the img is colored or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below codeline is for the drawing any shape on the eye or mouth in the image\n",
    "cv2.rectangle(img,(300,130),(390,210),(0,0,255),3)  #cv2.circle(img.(300,210),50,(80,30,180),5)  #cv2.line(img,(50,450),(0,0,255),10)\n",
    "cv2.imshow('Katrina_Kaif', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.waitKey(0)  #load image and wait until not closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('abc.jpg', img)  #saves the grascale image\n",
    "cv2.destroyAllWindows()   #for memory release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code for opening up the camera and pressing the key 'q' to stop it and save the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam=cv2.VideoCapture(0)  #0 for video capturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "while cam.isOpened():\n",
    "    index, img=cam.read()\n",
    "    if index:\n",
    "        nimg = cv2.cvtColor(img, cv2.IMREAD_COLOR)\n",
    "        cv2.imshow('frame', nimg)\n",
    "        cv2.imwrite('abc.jpg', nimg)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):          #waitKey(1)- unloads the image\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code for detecting the  face while the camera is running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "cascade= cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")    #drop the xml file from classroom to users/radhika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CascadeClassifier 0000019967691F50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, img= cam.read()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = cascade.detectMultiScale(gray,1.3,5,minSize=(30,30))\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+h,y+h),(0,255,0),2)\n",
    "    cv2.imshow('Faces', img)\n",
    "    if (cv2.waitKey(1) == ord('q')):\n",
    "        break\n",
    "        \n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
